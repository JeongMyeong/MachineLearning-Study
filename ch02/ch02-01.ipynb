{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scikit-learn (사이킷런)\n",
    "- 머신러닝을 위한 다양한 알고리즘과 개발을 위한 편리한 프레임워크,API를 제공\n",
    "#### 설치방법  \n",
    "conda install scikit-learn  혹은  \n",
    "pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iris 데이터로 연습해보기\n",
    "- iris 데이터 세트로 iris의 품종을 분류(Classification) 하는 문제\n",
    "- 분류는 대표적인 지도학습\n",
    "- 데이터의 피쳐와 정답인 label을 통해 모델을 학습시킨 뒤 모델에 테스트 데이터 입력을 통해 예측 값 결과를 낸다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris # 사이킷런에서 제공되는 iris 데이터를 로드하기 위해 import\n",
    "from sklearn.tree import DecisionTreeClassifier      #의사결정트리분류 알고리즘\n",
    "from sklearn.model_selection import train_test_split # 훈련데이터, 테스트 데이터 분리를 도와줌\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris target값 :  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "iris target명 :  ['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 붓꽃 데이터를 로드\n",
    "iris = load_iris()\n",
    "# iris.data는 Iris 데이터 세트에서 피처만으로 된 데이터를 numpy로 가지고 있음\n",
    "iris_data = iris.data\n",
    "\n",
    "# iris.target은 iris 데이터 세트에서 레이블(정답) 데이터를 numpy로 가지고 있음\n",
    "iris_label = iris.target\n",
    "print('iris target값 : ', iris_label)\n",
    "print('iris target명 : ', iris.target_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 붓꽃 데이터 세트를 DataFrame 형태로 변환\n",
    "iris_df = pd.DataFrame(data=iris_data, columns=iris.feature_names)\n",
    "iris_df['label'] = iris.target\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### label의 값에따른 종류\n",
    "label|종류|\n",
    " ---|---|\n",
    " 0|Setosa|\n",
    " 1|versicolor|\n",
    " 2|virginica|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train_test_split 함수를 통해 훈련/테스트 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(iris_data, iris_label, test_size=0.2, random_state=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 학습데이터로 DecisionTreeClassifier 알고리즘으로 학습시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=11,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DecisionTreeClassifier 객체 생성\n",
    "dt_clf = DecisionTreeClassifier(random_state=11)\n",
    "\n",
    "# 학습\n",
    "dt_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 완료된 DecisionTreeClassifier 객체에서 테스트 데이터로 예측\n",
    "pred = dt_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 1, 1, 2, 0, 1, 0, 0, 1, 1, 1, 1, 2, 2, 0, 2, 1, 2, 2, 1, 0,\n",
       "       0, 1, 0, 0, 2, 1, 0, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 훈련된 모델로 예측된 값들\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예측 성능을 평가해보기\n",
    "- 사이킷런에서 제공하는 accuracy_score() 함수를 사용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도 : 0.9333\n"
     ]
    }
   ],
   "source": [
    "# 정답과 예측한 값으로 정확도를 확인\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"예측 정확도 : {:.4f}\".format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iris 데이터 종류 분류 문제를 해결한 과정\n",
    "- 1) 데이터 세트 분리 : 데이터를 훈련/테스트 데이터로 분리\n",
    "- 2) 모델 학습 : 훈련데이터를 ML 알고리즘을 적용해 모델을 학습\n",
    "- 3) 훈련된 모델로 예측 수행 : 학습된 ML 모델을 이용하여 테스트 데이터를 입력하여 예측을 수행\n",
    "- 4) 평가 : 예측된 결괏값과 실제 결괏값을 비교하여 ML 모델 성능을 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimator /  fit(), predict() 메소드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 사이킷런은 fit()과 predict()만을 이용해 간단하게 학습과 예측결과를 반환\n",
    "- 분류 알고리즘을 구현한 클래스는 Classifier로, 회귀 알고리즘을 구현한 클래스를 Regressor 로 지칭함\n",
    "- Classifier 와 Regressor 를 합쳐 Estimator 라 부른다.\n",
    "- cross_val_score(교차검증), GridSearchCV(하이퍼파라미터 튜닝) 클래스는 Estimator를 인자로 받음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 머신러닝 모델을 구축하는 주요 프로세스\n",
    "- 데이터 전처리\n",
    "- ML 알고리즘 학습/예측/평가를 반복"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection 모듈\n",
    "- train_test_split()\n",
    "- 교차검증\n",
    "- 하이퍼 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 교차검증\n",
    "- 훈련/테스트 셋을 나누더라도 과적합에 취약한 약점이 존재한다.\n",
    "- K폴드 교차검증\n",
    "> - 5 폴드 교차검증 (k가 5)  \n",
    "> - 데이터 세트를 5등분 하여 4개등분을 학습데이터세트로, 1개등분은 검증데이터 세트로 설정하여 학습데이터 세트에서 학습 수행 검증데이터 세트에서 평가를 수행  \n",
    "> - 5번 반복된다.\n",
    "- 사이킷 런에서는 K 폴드 교차 검증 프로세스를 구현하기 위해 KFold 와 StratifiedKFold 클래스를 제공한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "iris = load_iris()\n",
    "features = iris.data\n",
    "label = iris.target\n",
    "dt_clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# 5개의 폴드 세트로 분리하는 KFold 객체와 폴드 세트별 정확도를 담을 리스트 객체를 생성\n",
    "kfold = KFold(n_splits=5)\n",
    "cv_accuracy=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " #1 교차 검증 정확도 : 1.0, 학습데이터 크기 :  120 검증데이터 크기 : 30\n",
      "\n",
      " #2 교차 검증 정확도 : 1.0, 학습데이터 크기 :  120 검증데이터 크기 : 30\n",
      "\n",
      " #3 교차 검증 정확도 : 0.8333, 학습데이터 크기 :  120 검증데이터 크기 : 30\n",
      "\n",
      " #4 교차 검증 정확도 : 0.9333, 학습데이터 크기 :  120 검증데이터 크기 : 30\n",
      "\n",
      " #5 교차 검증 정확도 : 0.8, 학습데이터 크기 :  120 검증데이터 크기 : 30\n",
      "\n",
      " ## 평균 검증 정확도 :  0.91332\n"
     ]
    }
   ],
   "source": [
    "n_iter = 0\n",
    "\n",
    "# KFold 객체의 split()를 호출하면 폴드 별 학습용, 검증용 테스트의 로우 인덱스를 array로 반환한다\n",
    "for train_index, test_index in kfold.split(features):\n",
    "    # kfold.split()으로 반환된 인덱스를 이용해 학습용, 검증용 테스트 데이터 추출\n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = label[train_index], label[test_index]\n",
    "    \n",
    "    # 학습 및 예측\n",
    "    dt_clf.fit(X_train, y_train)\n",
    "    pred = dt_clf.predict(X_test)\n",
    "    n_iter +=1\n",
    "    \n",
    "    # 반복 시 마다 정확도 측정\n",
    "    accuracy = np.round(accuracy_score(y_test, pred),4 )\n",
    "    train_size = X_train.shape[0]\n",
    "    test_size = X_test.shape[0]\n",
    "    \n",
    "    print(\"\\n #{} 교차 검증 정확도 : {}, 학습데이터 크기 :  {} 검증데이터 크기 : {}\".format(n_iter, accuracy, train_size, test_size))\n",
    "    cv_accuracy.append(accuracy)\n",
    "    \n",
    "# 개별 iteration 별 정확도를 합하여 평균 정확도를 계산\n",
    "print(\"\\n ## 평균 검증 정확도 : \", np.mean(cv_accuracy))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stratified KFold\n",
    "- 불균형한 분포도를 가진 레이블 데이터 집합을 위한 K폴드 방식\n",
    "- 대출 사기 데이터를 예측한다고 가정하고 데이터 세트는 1억건이 있다.\n",
    "- 레이블(정답) : 대출사기=1, 정상대출=0\n",
    "- 대부분의 데이터는 정상대출일 것이다. 이중 대출사기가 약 1000건이라 치면 아주 작은 확률로 대출사기 레이블이 존재하는 것이다.\n",
    "- 이렇게 작은 비율로 1레이블 값이 있으면 K폴드로 랜덤하게 학습 및 테스트 인덱스를 골라도 0과 1의 비율을 제대로 반영하지 못하는 경우가 많다.\n",
    "- Straified KFold 는 이처럼 한쪽으로 값이 치우쳐 있을때 사용하기 좋다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iris 데이터세트를 DataFrame으로 생성하고 레이블 값의 분포도를 확인한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    50\n",
       "1    50\n",
       "0    50\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "iris = load_iris()\n",
    "iris_df = pd.DataFrame(data=iris.data, columns = iris.feature_names)\n",
    "iris_df['label'] = iris.target\n",
    "iris_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 레이블 분포는 모두 50개로 같다\n",
    "- 문제를 발생 시키기 위해 3개의 폴드 세트를 KFold로 생 성하고 각 폴드마다 데이터 값의 분포도를 확인 해보도록 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 교차 검증 : 1\n",
      "학습 레이블 데이터 분포 : \n",
      "2    50\n",
      "1    50\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포 : \n",
      "0    50\n",
      "Name: label, dtype: int64\n",
      "## 교차 검증 : 2\n",
      "학습 레이블 데이터 분포 : \n",
      "2    50\n",
      "0    50\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포 : \n",
      "1    50\n",
      "Name: label, dtype: int64\n",
      "## 교차 검증 : 3\n",
      "학습 레이블 데이터 분포 : \n",
      "1    50\n",
      "0    50\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포 : \n",
      "2    50\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "n_iter = 0\n",
    "for train_index, test_index in kfold.split(iris_df):\n",
    "    n_iter+=1\n",
    "    label_train = iris_df['label'].iloc[train_index]\n",
    "    label_test = iris_df['label'].iloc[test_index]\n",
    "    print(\"## 교차 검증 : {}\".format(n_iter))\n",
    "    print(\"학습 레이블 데이터 분포 : \\n{}\".format(label_train.value_counts()))\n",
    "    print(\"검증 레이블 데이터 분포 : \\n{}\".format(label_test.value_counts()))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 첫 번째 교차검증에서 학습 레이블의 1,2 값이 각각 50개 추출되었고 검증레이블엔 0의 값이 50개 추출 되었다.\n",
    "- 0의 값은 전혀 학습이 되지 않고 있다.\n",
    "- StratifiedKFold 는 이렇게 KFold로 분할된 레이블 데이터 세트가 전체 레이블 값의 분포도를 반영하지 못하는 문제를 해결해준다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 교차 검증 : 1\n",
      "학습 레이블 데이터 분포 : \n",
      "2    33\n",
      "1    33\n",
      "0    33\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포 : \n",
      "2    17\n",
      "1    17\n",
      "0    17\n",
      "Name: label, dtype: int64\n",
      "## 교차 검증 : 2\n",
      "학습 레이블 데이터 분포 : \n",
      "2    33\n",
      "1    33\n",
      "0    33\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포 : \n",
      "2    17\n",
      "1    17\n",
      "0    17\n",
      "Name: label, dtype: int64\n",
      "## 교차 검증 : 3\n",
      "학습 레이블 데이터 분포 : \n",
      "2    34\n",
      "1    34\n",
      "0    34\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포 : \n",
      "2    16\n",
      "1    16\n",
      "0    16\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "n_iter=0\n",
    "\n",
    "for train_index, test_index in skf.split(iris_df, iris_df['label']):\n",
    "    n_iter+=1\n",
    "    label_train = iris_df['label'].iloc[train_index]\n",
    "    label_test = iris_df['label'].iloc[test_index]\n",
    "    \n",
    "    print(\"## 교차 검증 : {}\".format(n_iter))\n",
    "    print(\"학습 레이블 데이터 분포 : \\n{}\".format(label_train.value_counts()))\n",
    "    print(\"검증 레이블 데이터 분포 : \\n{}\".format(label_test.value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- 출력 결과를 보면 레이블 데이터 값의 분포도가 동일하다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 교차 검증을 보다 간편하게 해주는 cross_val_score() 함수\n",
    "- cross_val_score는 내부적으로 StratifiedKFold 를 이용한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증별 정확도 [0.9804 0.9216 0.9792]\n",
      "평균 검증 정확도 0.9604\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris_data = load_iris()\n",
    "dt_clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "data = iris_data.data\n",
    "label = iris_data.target\n",
    "\n",
    "# 성능 지표는 정확도, 교차 검증 세트는 3개\n",
    "scores = cross_val_score(dt_clf, data, label, scoring='accuracy', cv=3)\n",
    "print(\"교차 검증별 정확도\", np.round(scores,4))\n",
    "print(\"평균 검증 정확도\", np.round(np.mean(scores),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 교차 검증과 하이퍼 파라미터 튜닝을 한번에 해결해주는 GridSearchCV\n",
    "- GridSearchCV는 교차검증을 기반으로 하이퍼 파라미터의 최적값을 찾는다.\n",
    "- 튜닝하고자 하는 파라미터의 종류가 많아질수록 수행시간이 오래 걸린다.\n",
    "- estimator, param_grid, scoring, cv, refit 등의 파라미터가 들어간다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예시\n",
    "grid_parameters = {\"max_depth\":[1,2,3],\n",
    "                   \"min_samples_split\" : [2,3]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongmyeong/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/jeongmyeong/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/jeongmyeong/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/jeongmyeong/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/jeongmyeong/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 2}</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 3}</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 2}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 3}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 2}</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 3}</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     params  mean_test_score  rank_test_score  \\\n",
       "0  {'max_depth': 1, 'min_samples_split': 2}         0.700000                5   \n",
       "1  {'max_depth': 1, 'min_samples_split': 3}         0.700000                5   \n",
       "2  {'max_depth': 2, 'min_samples_split': 2}         0.958333                3   \n",
       "3  {'max_depth': 2, 'min_samples_split': 3}         0.958333                3   \n",
       "4  {'max_depth': 3, 'min_samples_split': 2}         0.975000                1   \n",
       "5  {'max_depth': 3, 'min_samples_split': 3}         0.975000                1   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  \n",
       "0              0.700                0.7               0.70  \n",
       "1              0.700                0.7               0.70  \n",
       "2              0.925                1.0               0.95  \n",
       "3              0.925                1.0               0.95  \n",
       "4              0.975                1.0               0.95  \n",
       "5              0.975                1.0               0.95  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, test_size=0.2, random_state=121)\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "\n",
    "### 파라미터를 딕셔너리 형태로 설정\n",
    "parameters = {\"max_depth\":[1,2,3], \"min_samples_split\":[2,3]}\n",
    "\n",
    "# param_grid의 하이퍼 파라미터를 3개의 train, test set fold로 나누어 테스트 수행 설정.\n",
    "### refit=True가 default 이다. True이면 가장 좋은 파라미터 설정으로 재학습 시킴.\n",
    "\n",
    "grid_dtree = GridSearchCV(dtree, param_grid=parameters, cv=3, refit=True)\n",
    "\n",
    "# iris 학습 데이터로 param_grid의 하이퍼 파라미터를 순차적으로 학습/평가\n",
    "grid_dtree.fit(X_train, y_train)\n",
    "\n",
    "# GridSearchCV 결과를 추출해 DataFrame으로 변환\n",
    "scores_df = pd.DataFrame(grid_dtree.cv_results_)\n",
    "scores_df[['params', 'mean_test_score', 'rank_test_score', 'split0_test_score', 'split1_test_score','split2_test_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 총 6개의 결과를 볼 수 있고 6번 파라미터를 변경하면서 학습 및 평가를 수행했음을 나타낸다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV 최적 파라미터 : {'max_depth': 3, 'min_samples_split': 2}\n",
      "GridSearchCV 최고 정확도 : 0.9750\n"
     ]
    }
   ],
   "source": [
    "print(\"GridSearchCV 최적 파라미터 : {}\".format(grid_dtree.best_params_))\n",
    "print(\"GridSearchCV 최고 정확도 : {:.4f}\".format(grid_dtree.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터 세트 정확도 : 0.9667\n"
     ]
    }
   ],
   "source": [
    "# GridSearchCV의 refit으로 이미 학습된 estimator 반환\n",
    "estimator = grid_dtree.best_estimator_\n",
    "\n",
    "# GridSearchCV의 best_estimator_는 이미 최적 학습 되어있으므로 별도 학습이 필요없다.\n",
    "pred = estimator.predict(X_test)\n",
    "print(\"테스트 데이터 세트 정확도 : {:.4f}\".format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
