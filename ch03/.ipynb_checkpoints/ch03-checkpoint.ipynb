{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 분류의 성능 평가 지표\n",
    "- 정확도(Accuracy)\n",
    "- 오차행렬(Confusion Matrix)\n",
    "- 정밀도(Precision)\n",
    "- 재현율(Recall)\n",
    "- F1 스코어\n",
    "- ROC AUC\n",
    "\n",
    "#### 위에 언급된 분류의 성능지표는 이진/멀티 분류 모두 적용되지만 특히 이진분류에서 더욱 중요하게 강조하는 지표이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정확도\n",
    "- 정확도는 직관적으로 모델 예측 성능을 나타내는 평가지표.\n",
    "- 데이터의 구성에 따라 ML모델의 성능을 왜곡할 수 있기 때문에 정확도 수치 하나만 가지고 성능을 평가하지는 않는다.\n",
    "- ML알고리즘을 적용한 후 예측 정확도가 80%대 였지만 탑승객이 남자인 경우보다 여자인 경우에 생존확률이 높았기 때문에 무조건 성별이 여자인 경우 생존으로, 남자인 경우 사망으로 예측 결과를 예측해도 이와 비슷한 수치가 나올 수 잇다.\n",
    "- 사이킷런의 BaseEstimator 클래스를 상속받아 아무런 학습 하지 않고 성별에 따라 생존자를 예측하는 단순한 Classifier를 생성한다.\n",
    "- 사이킷런은 BaseEstimator를 상속받으면 Customized 형태의 Estimator를 개발자가 생성할 수 있다.\n",
    "- 단순히 Sex 피처가 1이면 0, 그렇지않으면 1로 예측하는 매우 단순한 Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class MyDummyClassifier(BaseEstimator):\n",
    "    # fit() 메소드는 아무것도 학습하지 않는다.\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    # predict() 메소드는 단순히 Sex 피처가 1이면 0, 그렇지 않으면 1로 예측\n",
    "    def predict(self, X):\n",
    "        pred = np.zeros( (X.shape[0], 1))\n",
    "        for i in range(X.shape[0]):\n",
    "            if X['Sex'].iloc[i] == 1:\n",
    "                pred[i] = 0\n",
    "            else:\n",
    "                pred[i] = 1\n",
    "        return pred\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 생성된 MyDummyClassifier를 이용하여 타이타닉 생존자 예측을 수행해본다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Null 처리 함수\n",
    "def fillna(df):\n",
    "    df['Age'].fillna(df['Age'].mean(),inplace=True)\n",
    "    df['Cabin'].fillna('N', inplace=True)\n",
    "    df['Embarked'].fillna('N', inplace=True)\n",
    "    df['Fare'].fillna(0, inplace=True)\n",
    "    return df\n",
    "\n",
    "# 불필요한 속성삭제\n",
    "def drop_features(df):\n",
    "    df.drop(['PassengerId','Name','Ticket'], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "# 레이블 인코딩\n",
    "def format_features(df):\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    df['Cabin'] = df['Cabin'].str[:1]\n",
    "    features = ['Cabin', 'Sex', 'Embarked']\n",
    "    for feature in features:\n",
    "        le = LabelEncoder()\n",
    "        le = le.fit(df[feature])\n",
    "        df[feature] = le.transform(df[feature])\n",
    "    return df\n",
    "\n",
    "# 앞에서 설정한 데이터 전처리 함수 호출\n",
    "def transform_features(df):\n",
    "    df = fillna(df)\n",
    "    df = drop_features(df)\n",
    "    df = format_features(df)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "titanic_df = pd.read_csv(\"../ch02/train.csv\")\n",
    "y_titanic_df = titanic_df['Survived']\n",
    "X_titanic_df = titanic_df.drop('Survived',axis=1)\n",
    "X_titanic_df = transform_features(X_titanic_df)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Classifier의 정확도는 : 0.7821\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "myclf = MyDummyClassifier()\n",
    "myclf.fit(X_train, y_train)\n",
    "\n",
    "mypredictions = myclf.predict(X_test)\n",
    "print('Dummy Classifier의 정확도는 : {:.4f}'.format(accuracy_score(y_test, mypredictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이렇게 단순한 알고리즘으로 예측해도 78%로 꽤 높은 수치가 나온다.\n",
    "- 그러므로 정확도를 평가지표로 사용할 때는 신중해야한다.\n",
    "- 특히 imbalanced 레이블 값 분포에서 ML모델의 성능을 판단할 때 적합한 평가지표가 아니다\n",
    "- 예를들어 100개의 데이터에 90개의 레이블이 0, 10개만 1이라고 하면 무조건 0으로 예측결과를 반환하는  ML 모델의 경우 정확도가 90%가 된다.\n",
    "- 예제코드로 확인해 본다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class MyFakeClassifier(BaseEstimator):\n",
    "    def fit(self, X, y):\n",
    "        pass\n",
    "    \n",
    "    # 입력값으로 들어오는걸 모두 0으로 만들어 반환\n",
    "    def predict(self, X):\n",
    "        return np.zeros( (len(X), 1), dtype=bool)\n",
    "    \n",
    "digits = load_digits()\n",
    "\n",
    "y = (digits.target == 7).astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split( digits.data, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "레이블 테스트 세트 크기 : (450,)\n",
      "테스트 세트 레이블 0과 1의 분포도\n",
      "0    409\n",
      "1     41\n",
      "dtype: int64\n",
      "모든 예측을 0으로 하여도 정확도는 : 0.909\n"
     ]
    }
   ],
   "source": [
    "print('레이블 테스트 세트 크기 :', y_test.shape)\n",
    "print('테스트 세트 레이블 0과 1의 분포도')\n",
    "print(pd.Series(y_test).value_counts())\n",
    "\n",
    "fakeclf = MyFakeClassifier()\n",
    "fakeclf.fit(X_train, y_train)\n",
    "fakepred = fakeclf.predict(X_test)\n",
    "print('모든 예측을 0으로 하여도 정확도는 : {:.3f}'.format(accuracy_score(y_test, fakepred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 단순히 모두 0 값으로 반환함에도 불구하고 450개의 테스트 데이터 세트에 수행한 예측 정확도는 90%를 넘는다.\n",
    "- 이처럼 정확도 평가 지표는 불균형한 레이블 데이터 세트에서는 성능 수치로 사용돼서는 안된다.\n",
    "- 이런 한계점을 극복하기 위해 여러가지 분류지표와 함께 적용한다.\n",
    "- True/False, Positive/Negative의 오차행렬이 있다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 오차행렬  \n",
    "TN FP  \n",
    "FN FP  \n",
    "\n",
    "- 행이 실제 클래스 열이 예측 클래스\n",
    "\n",
    "\n",
    "- TN : 예측값을 Negative값 0 으로 예측했고 실제 값 역시 Negative 값 0\n",
    "- FP : 예측값을 Positive값 1 로 예측했는데 실제 값은 Negative 값 0\n",
    "- FN : 예측값을 Negative값 0 으로 예측했는데 실제 값은 Positive 값 1\n",
    "- TP : 예측값을 Positive값 1 로 예측했는데 실제 값 역시 Positive 값 1  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### 위의 MyFakeClassifier의 예측 성능 지표를 오차 행렬로 표현해 본다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[409,   0],\n",
       "       [ 41,   0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, fakepred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TN은 409\n",
    "- FP는 0\n",
    "- FN은 41\n",
    "- TP는 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정밀도와 재현율\n",
    "- 정밀도 : TP / (FP+TP)\n",
    "        예측을 Positive로 한 대상 중에 예측과 실제 값이 Positive로 일치한 데이터의 비율\n",
    "        Positive 예측 성능을 더욱 정밀하게 측정하기 위한 평가 지표로 양성 예측도라고도 함\n",
    "- 재현율 : TP / (FN+TP)\n",
    "        실제 값이 Positive인 대상 중에 예측과 실제 값이 Positive로 일치한 데이터의 비율\n",
    "        민감도 또는 TPR(True Positive Rate) 라고도 불림\n",
    "- 재현율이 중요 지표인 경우는 실제 Positive 양성 데이터를 Negative로 잘못 판단하게 되면 업무상 큰 영향이 발생하는 경우\n",
    "        ex) 실제 Positive인 암 환자를 Positive 양성이 아닌 Negative 음성으로 잘못 판단 했을 경우 \n",
    "        보험사기와 같은 금융 사기 적발 모델도 재현율이 중요하다. 실제 금융거래 사기인 positive 건을 negative로 잘못 판단하게 되면 회사에 미치는 손해가 크다.\n",
    "- 보통은 재현율이 정밀도보다 상대적으로 중요한 업무가 많지만 정밀도가 더 중요한 지표인 경우도 있다.\n",
    "        ex) 스팸메일 여부를 판단하는 모델의 경우 실제 Positive인 스팸 메일을 Negative인 일반 메일로 분류해도 사용자가 불편함을 느끼는 정도지만 그 반대일 경우 메일을 아예 받지 못하게 돼 업무에 차질이 생긴다\n",
    "        \n",
    "- 재현율 : 실제 Positive 양성인 데이터 예측을 Negative로 잘못 판단하게 되면 업무상 큰 영향이 발생할 때\n",
    "- 정밀도 : 실제 Negative 음성인 데이터 예측을 Positive 양성으로 잘못 판단하게 되면 업무상 큰 영향이 발생할 때\n",
    "- 가장 좋은 성능 평가는 재현율과 정밀도 모두 높은 수치를 얻는 것.\n",
    "- 사이킷런은 정밀도 계산을 위해 precision_score()를, 재현율 계산을 위해 recall_score()를 API로 제공\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가하는 API를 한 번에 호출하는 get_clf_eval() 함수를 작성.\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "def get_clf_eval(y_test, pred):\n",
    "    confusion = confusion_matrix(y_test, pred)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    print(\"정확도 : {:.4f}, 정밀도 : {:.4f}, 재현율 : {:.4f}\".format(accuracy, precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[108  10]\n",
      " [ 14  47]]\n",
      "정확도 : 0.8659, 정밀도 : 0.8246, 재현율 : 0.7705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongmyeong/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# 로지스틱 회귀 기반으로 타이타닉 생존자를 예측하고 평가를 수행\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 원본 데이터를 재로딩, 데이터 가공, 학습 데이터/테스트 데이터 분할\n",
    "titanic_df = pd.read_csv('../ch02/train.csv')\n",
    "y_titanic_df = titanic_df['Survived']\n",
    "X_titanic_df = titanic_df.drop('Survived', axis=1)\n",
    "X_titanic_df = transform_features(X_titanic_df)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df, test_size=0.2, random_state=11)\n",
    "lr_clf = LogisticRegression()\n",
    "\n",
    "lr_clf.fit(X_train, y_train)\n",
    "pred = lr_clf.predict(X_test)\n",
    "get_clf_eval(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정밀도/재현율 트레이드 오프\n",
    "- 정밀도 재현율 어느 한 쪽을 강제로 높이면 다른 하나의 수치는 떨어지기 쉽다. 이를 정밀도 재현율의 트레이드 오프(Trade-off)라고 부른다.\n",
    "- 사이킷런은 개별 데이터별로 예측 확률을 반환하는 메서드인 predict_proba() 를 제공한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_proba()결과 shape : (179, 2)\n",
      "pred_proba array에서 앞 3개만 샘플로 추출 \n",
      ": [[0.44935227 0.55064773]\n",
      " [0.86335512 0.13664488]\n",
      " [0.86429645 0.13570355]]\n",
      "두 개의 class 중에서 더 큰 확률을 클래스 값으로 예측\n",
      " [[0.44935227 0.55064773 1.        ]\n",
      " [0.86335512 0.13664488 0.        ]\n",
      " [0.86429645 0.13570355 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "pred_proba = lr_clf.predict_proba(X_test)\n",
    "pred = lr_clf.predict(X_test)\n",
    "print(\"pred_proba()결과 shape : {}\".format(pred_proba.shape))\n",
    "print(\"pred_proba array에서 앞 3개만 샘플로 추출 \\n:\", pred_proba[:3])\n",
    "\n",
    "# 예측 확률 array와 예측 결괏값 array를 병합(concatenate)해 예측 확률과 결괏값을 한눈에 확인\n",
    "pred_proba_result = np.concatenate([pred_proba, pred.reshape(-1, 1)], axis=1)\n",
    "print('두 개의 class 중에서 더 큰 확률을 클래스 값으로 예측\\n', pred_proba_result[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- predict() 메서드는 predict_proba() 메서드에 기반해 생성된 API 이다.\n",
    "- 이를 이해하는 것은 사이킷런이 어떻게 정밀도/재현율 트레이드오프를 구현했는지를 이해하는 데 도움을 준다.\n",
    "- 사이킷런은 분류 결정 임곗값을 조정해 정밀도와 재현율의 성능 수치를 상호 보완적으로 조정할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[108  10]\n",
      " [ 14  47]]\n",
      "정확도 : 0.8659, 정밀도 : 0.8246, 재현율 : 0.7705\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "# Binarizer의 threshold 설정값.\n",
    "custom_threshold = 0.5\n",
    "\n",
    "# predict_proba() 반환 값의 두 번째 칼럼, 즉 Positive 클래스 칼럼 하나만 추출해 Binarizer를 적용\n",
    "pred_proba_1 = pred_proba[:,1].reshape(-1,1)\n",
    "\n",
    "binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_1)\n",
    "custom_predict = binarizer.transform(pred_proba_1)\n",
    "\n",
    "get_clf_eval(y_test, custom_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 분류 결정 임곗값을 낮추면 평가 지표가 어떻게 변할까 ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[97 21]\n",
      " [11 50]]\n",
      "정확도 : 0.8212, 정밀도 : 0.7042, 재현율 : 0.8197\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "# Binarizer의 threshold 설정값.\n",
    "custom_threshold = 0.4\n",
    "\n",
    "# predict_proba() 반환 값의 두 번째 칼럼, 즉 Positive 클래스 칼럼 하나만 추출해 Binarizer를 적용\n",
    "pred_proba_1 = pred_proba[:,1].reshape(-1,1)\n",
    "\n",
    "binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_1)\n",
    "custom_predict = binarizer.transform(pred_proba_1)\n",
    "\n",
    "get_clf_eval(y_test, custom_predict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 임곗값을 낮추니 재현율 값이 올라가고 정밀도가 떨어졌다.\n",
    "- positive 예측값이 많아지면 상대적으로 재현율 값이 높아진다.\n",
    "- 양성 예측을 많이 하다 보니 실제 양성을 음성으로 예측하는 횟수가 상대적으로 줄어들기 때문."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임곗값 :  0.4\n",
      "오차 행렬\n",
      "[[97 21]\n",
      " [11 50]]\n",
      "정확도 : 0.8212, 정밀도 : 0.7042, 재현율 : 0.8197\n",
      "임곗값 :  0.45\n",
      "오차 행렬\n",
      "[[105  13]\n",
      " [ 13  48]]\n",
      "정확도 : 0.8547, 정밀도 : 0.7869, 재현율 : 0.7869\n",
      "임곗값 :  0.5\n",
      "오차 행렬\n",
      "[[108  10]\n",
      " [ 14  47]]\n",
      "정확도 : 0.8659, 정밀도 : 0.8246, 재현율 : 0.7705\n",
      "임곗값 :  0.55\n",
      "오차 행렬\n",
      "[[111   7]\n",
      " [ 16  45]]\n",
      "정확도 : 0.8715, 정밀도 : 0.8654, 재현율 : 0.7377\n",
      "임곗값 :  0.6\n",
      "오차 행렬\n",
      "[[113   5]\n",
      " [ 17  44]]\n",
      "정확도 : 0.8771, 정밀도 : 0.8980, 재현율 : 0.7213\n"
     ]
    }
   ],
   "source": [
    "# 임곗값을 0.4 에서 0.6까지 0.05씩 증가시키며 평가 지표를 조사해본다.\n",
    "# 이를 위해 get_eval_by_threshold() 함수를 작성\n",
    "\n",
    "thresholds = [0.4, 0.45, 0.5, 0.55, 0.6]\n",
    "\n",
    "def get_eval_by_threshold(y_test, pred_proba_c1, thresholds):\n",
    "    for custom_threshold in thresholds:\n",
    "        binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_c1)\n",
    "        custom_predict = binarizer.transform(pred_proba_c1)\n",
    "        print('임곗값 : ', custom_threshold)\n",
    "        get_clf_eval(y_test, custom_predict)\n",
    "        \n",
    "get_eval_by_threshold(y_test, pred_proba[:,1].reshape(-1,1), thresholds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 임곗값 변화에 따른 평가 지표 값.\n",
    "- 사이킷런은 이와 유사한 precision_recall_curve() API를 제공.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "반환된 분류 결정 임곗값 배열의 Shape :  (147,)\n",
      "샘플 추출을 위한 임곗값 배열의 index 10개: [  0  15  30  45  60  75  90 105 120 135]\n",
      "샘플용 10개의 임곗값 :  [0.12 0.13 0.15 0.17 0.26 0.38 0.49 0.63 0.76 0.9 ]\n",
      "샘플 임계값별 정밀도 :  [0.379 0.424 0.455 0.519 0.618 0.676 0.797 0.93  0.964 1.   ]\n",
      "샘플 임계값별 재현율 :  [1.    0.967 0.902 0.902 0.902 0.82  0.77  0.656 0.443 0.213]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "# 레이블 값이 1일 때의 예측 확률 추출\n",
    "pred_proba_class1 = lr_clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "# 실제값 데이터 세트와 레이블 값이 1일 때의 예측 확률을 precision_recall_curve 인자로 입력\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, pred_proba_class1)\n",
    "print('반환된 분류 결정 임곗값 배열의 Shape : ', thresholds.shape)\n",
    "\n",
    "# 반환된 임계값 배열 row가 147건 이므로 샘플로 10건만 추출하되, 임곗값을 15 step으로 추출\n",
    "thr_index = np.arange(0, thresholds.shape[0], 15)\n",
    "print('샘플 추출을 위한 임곗값 배열의 index 10개:', thr_index)\n",
    "print('샘플용 10개의 임곗값 : ', np.round(thresholds[thr_index],2))\n",
    "\n",
    "# 15 step 단위로 추출된 임계값에 따른 정밀도와 재현율 값\n",
    "print('샘플 임계값별 정밀도 : ', np.round(precisions[thr_index], 3))\n",
    "print('샘플 임계값별 재현율 : ', np.round(recalls[thr_index],3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 추출된 임곗값 샘플 10개에 해당하는 정밀도 값과 재현율 값을 보면 임곗값이 증가할수록 정밀도 갑승ㄴ 동시에 높아지거나 재현율 값은 낮아짐을 알 수 있다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
